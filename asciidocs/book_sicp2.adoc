= Structure and interpretation of computer programs Part 2: Building abstractions with data
:toc:

So far we've looked at procedural abstractions operating on numerical data. Usually, we'll need to build more complex abstractions on data types themselves. In particular, _compound data types_. Similarly to procedural abstractions, this will allow us to elevate the conceptual level at which we can design our programs.

Consider rational numbers (i.e. those that can be expressed as x/y, where x and y are integers). We could design a program where we we deal with and track numerators and denominators separately. But it would be better if we could 'glue together' the two numbers, and deal with them as a single thing, and we can separate how we deal with rational numbers from their concrete representation, such separation forming an *abstraction barrier* between different parts of a program.

== Introduction to data abstraction

A data abstraction is when you use compound data objects so that they operate on abstract data. The concrete data representation is defined independently from the programs that use the data. We use *selectors* and *constructors* to interface between the two thing.

Consider an API for a rational numbers abstraction:

[source,clojure]
----
(make-rat <n> <d>)
(numer <x>)
(denom <x>)
----

This is an example of the *wishful thinking* strategy. We haven't talked about how this will be implemented, only the operations we would like to use to interact with rationals. Using these, we can trivially implement higher level operations on rationals:

[source,clojure]
----
(defn add-r [x y] 
  (make-rat (+ (* (numer x1) (denom x2)) (* (numer x2) (denom x1))) 
            (* (denom x1) (denom x2))))
----

We can implement a data structure for rationals with a pair: 

[source,clojure]
----
(defn pair [a b] [a b])
(defn make-rat [n d] (pair n d)) 
(defn numer [x] (first x)) 
(defn denom [x] (second x)) 
----

Note that make-rat doesn't reduce its arguments to the gcd, but can be made to do so trivially.

We can envision this schema as a series of abstraction barriers, where at each level separated by a barrier, the level doesn't need to know how the implementation below it works. This makes programs easier to maintain and modify, since provided we don't change the API, we can change how lower level procedures are implemented without breaking the client.

----
=== Programs that use rational number ===
    Rational numbers in problem domain
========= add-rat, sub-rat etc. =========
    Rational numbers as numer / denom
======= make-rat, numer, denom ==========
       Rational numbers as pairs
========= pair, first, second ===========
    Language implementation of pair
----

It is worth pausing to consider what we mean by data. We implemented rationals with `pair` `first` and `second` above, but we don't know how the language implements them. We assume there is some underlying 'stuff' which allows us to glue together two numbers and then later retrieve them. In fact we can easily implement these without any such underlying data, using only procedures:

[source,clojure]
----
(defn pair [x y]
  (fn [m]
    (cond (= m 0) x
          (= m 1) y
          :else (throw (ex-info "Argument not 0 or 1" [x y m])))))

(defn first [z] (z 0))
(defn second [z] (z 1))
----

== Hierarchical data and the closure property

We've seen pairs are primitive glue we can use to make compound data.

image::../images/book_sicp/2_2_box1.gif[]

We can extend this to create more complicated things by having pairs of _pairs_. 

image::../images/book_sicp/2_2_box2.gif[]

This permits the creation of _hierarchical_ data structures: structures made up of parts which are themselves made up of parts.

The two most important structures we can create with nested pairs are *sequences* and *trees*.

=== Sequences

A sequence can be represented as a chain of pairs, where the first element is your data, and the second element is a pair, the first element of which is your data, the second element is a pair...etc.

image::../images/book_sicp/2_4_sequence.gif[]

This would be constructed using like

[source,clojure]
----
(pair 1
      (pair 2
            (pair 3
                  (pair 4 nil))))
;; => [1 [2 [3 [4 nil]]]]
----

Not the use of `nil` (from _nihil_, meaning "nothing") to terminate the list.

This sequence is call a _list_, or linked list. Clojure has a built in primitive `list` to help in constructing lists. The above can be described `(list 1 2 3 4)`

Note that in Clojure, lists are _not_ represented as a chain of pairs. So in SICP `cdr` can be equivalent to `second` or `rest` depending on the data structure.

We can manipulate lists by successively " `rest` ing down" the list. For example, to get the nth element of the list:

[source,clojure]
----
(defn list-ref [items n]
  (if (= n 0) (first items)
      (list-ref (rest items) (- n 1))))

(list-ref (list 1 4 9 16 25) 3) ;;=> 16
----

Sometimes you'll want to traverse the whole list, so you need to know when you're finished - which is signalled by the call to `rest` returning the empty list

[source,clojure]
----
(defn length [items]
  (if (empty? items) 0
      (+ 1 (length (rest items)))))

(length (list 1 3 5 7))
----

Another convention is to " `cons` up" an result list while `rest` ing down another one:

[source,clojure]
----
(defn append [list1 list2]
  (if (empty? list1) list2
      (cons (first list1) (append (rest list1) list2))))

(append (list 1 4 9 16 25) (list 1 3 5 7)) ;; => (1 4 9 16 25 1 3 5 7)
(append (list 1 3 5 7) (list 1 4 9 16 25)) ;; => (1 3 5 7 1 4 9 16 25)
----

(note: in Clojure, `cons` _is_ the right fn to use here, even though it hasn't been up to now. This is due to the differing implementations of lists in Scheme and Clojure).

Often we want to apply a transform to each element in a list. 

[source,clojure]
----
(defn scale-list [items factor]
  (if (empty? items) nil
      (cons (* (first items) factor)
            (scale-list (rest items) factor))))

(scale-list (list 1 2 3 4 5) 10)
----

This idea is useful enough that it can be abstracted into a higher order function called `map`

[source,clojure]
----
(defn map' [f items]
  (if (empty? items) nil
      (cons (f (first items))
            (map' f (rest items)))))

(map' (fn [item] (* item 10)) (list 1 2 3 4 5))

(defn scale-list [items factor]
  (map' (fn [x] (* x factor) items)))
----

(Note: though `map'` is defined here, for future examples, Clojure's built in `map` will be used)

`map` represents an important pattern, because it allows us to deal with lists at a higher level. In the original `scale-list` it was very explicit how we were looping through the sequence. `map` suppresses that detail. We are allowed to _think_ about the operation differently. `map` is a way of erecting an abstraction barrier that isolates implementation of procedures that transform lists from the detail of how lists are created and combined.  

=== Hierarchical structures

We saw that sequences can be thought of as chains of pairs, where the first element is scalar data, and the second is another pair (or nil). We can further generalise this by permitting the _first_ element to be a compound structure too. For example `(pair (list 1 2) (list 3 4))` could be thought of as 

image::../images/book_sicp/2_5_hier.gif[]

Or alternatively, as a _tree_

image::../images/book_sicp/2_6_tree.gif[]

Note that a tree consists of leaves (scalar data) and branches (compound glue). Note also that a tree can be thought of as consisting of sub-trees.

[source,clojure]
----
(defn count-leaves [tree]
  (cond (not (coll? tree)) 1
        (empty? tree) 0
        :else (+ (count-leaves (first tree))
                 (count-leaves (rest tree)))))

(length (list (list 1 2) 3 4)) ;; => 3
(count-leaves (list (list 1 2) 3 4)) ;; => 4
----

We can also use `map` together with recursion to deal with trees.

[source,clojure]
----
(defn scale-tree [tree factor]
  (map (fn [subtree]
         (if (coll? subtree) (scale-tree subtree factor)
             (* subtree factor)))
       tree))

(scale-tree '((1) 2 (3 4)) 3)
;; => ((3) 6 (9 12))
----

=== Sequences as conventional interfaces

Consider the procedures

[source,clojure]
----
(defn sum-odd-squares [tree]
  (cond (not (list? tree)) (if (odd? tree) (square tree) 0)
        (empty? tree) 0
        :else (+ (sum-odd-squares (first tree))
                 (sum-odd-squares (rest tree)))))

(sum-odd-squares '(1 2 3 4 5))
;; => 35

(defn even-fibs [n]
  (letfn [(next [k]
            (if (> k n) nil
                (let [f (fib k)]
                  (if (even? f) (cons f (next (inc k))) (next (+ k 1))))))]
    (next 0)))

(even-fibs 10)
;; => (0 2 8 34)
----

On the surface these would seem to have little in common. The first can be described as:

. enumerates the leaves of a tree as a sequence
. filters them, selecting the odd ones
. computes the square of each of the selected ones
. accumulates the results using +, starting a zero

The second as:

. enumerates the integers from 0 to n as a sequence
. computes the Fibonacci numbers for each integer
. filters them, selecting the even ones
. accumulates the results using cons, starting with the empty list

The first step is to create a sequence of values from our input data structure. These can be analogized as 'signals' flowing through a circuit, with stages implementing which transform those signals/sequences

image::../images/book_sicp/2_7_pipe.gif[]

The procedures defined above don't really reflect this blueprint. In `sum-odd-squares`, the enumeration is spread over the whole function. Everything is mixed together. If we could separate them, we could get the same conceptual clarity as in the flow chart.

Filter can be implemented thus:

[source,clojure]
----
(defn filter' [pred s]
  (cond (empty? s) nil
        (pred (first s)) (cons (first s) (filter' pred (rest s)))
        :else (filter' pred (rest s))))

(filter odd? (list 1 2 3 4 5))
;; => (1 3 5)
----

And accumulations like:

[source,clojure]
----
(defn accumulate [op init s]
  (if (empty? s) init
      (op (first s)
          (accumulate op init (rest s)))))

(accumulate + 0 (list 1 2 3 4 5))
;; => 15
----

Now we need the "enumerate" part - this will be different for different inputs, since this is how we 'transform' whatever we're given into sequences (implemented here as lists).

[source,clojure]
----
(defn enumerate-interval [low high]
  (if (> low high) nil
      (cons low (enumerate-interval (inc low) high))))

(enumerate-interval 4 10)
;; => (4 5 6 7 8 9 10)


(defn enumerate-tree [tree]
  (cond (not (coll? tree)) (list tree)
        (empty? tree) nil
        :else (concat (enumerate-tree (first tree))
                      (enumerate-tree (rest tree)))))

(enumerate-tree '(1 (2 3) 4 5 (6 7)))
;; => (1 2 3 4 5 6 7)
----

Now the functions can be restated as an almost 1:1 match with the signal-flow plans.

[source,clojure]
----
(defn even-fibs [n]
  (->> (enumerate-interval 0 n)
       (map fib)
       (filter even?)
       (accumulate cons '())))

(even-fibs 10)
;; => (0 2 8 34)

(defn even-fibs [n]
  (->> (enumerate-interval 0 n)
       (map fib)
       (filter even?)
       (accumulate cons '())))

(even-fibs 10)
;; => (0 2 8 34)
----

In programming languages with looping constructs it's common to have 'nested loops' to deal with things like 2d matrices. Consider the problem: Given a positive integer n, find all ordered pairs of distinct positive integers i and j, where 1<=j<i<=n, such that i + j is prime.

One way to do this, is to enumerate a sequence of pairs [i j], then test and filter each of these for primality.

We can generate a list of `i` with `(enumerate 1 n) ;;=> [1 2 3 4,,,]`. For each of these `i` (i.e. we want to map over the sequence of i's) we want to generate a sequence of pairs `[i j]`, where `1<=j<i`. We can do this with `(enumerate 1 (dec i))`.

This should lead us down the path of a nested map:

[source,clojure]
----
(map (fn [j] (list 5 j)) (enumerate-interval 1 (- 5 1))) ;; inner map, for i=5
;; => ((5 1) (5 2) (5 3) (5 4))

(map (fn [i] (map (fn [j] (list i j)) (enumerate-interval 1 (- i 1)))) ;; nested map
     (enumerate-interval 1 10))
;; => (()
;;     ((2 1))
;;     ((3 1) (3 2))
;;     ((4 1) (4 2) (4 3))
;;     ((5 1) (5 2) (5 3) (5 4))
;;     ((6 1) (6 2) (6 3) (6 4) (6 5))
;;     ((7 1) (7 2) (7 3) (7 4) (7 5) (7 6))
;;     ((8 1) (8 2) (8 3) (8 4) (8 5) (8 6) (8 7))
;;     ((9 1) (9 2) (9 3) (9 4) (9 5) (9 6) (9 7) (9 8))
;;     ((10 1) (10 2) (10 3) (10 4) (10 5) (10 6) (10 7) (10 8) (10 9)))
----

This isn't exactly what we want - we need to 'unnest' the resultant sequences. We can do by accumulate with `append`, initial `nil`.

[source,clojure]
----
(accumulate append
            nil
            (map (fn [i] (map (fn [j] (list i j)) (enumerate-interval 1 (- i 1))))
                 (enumerate-interval 1 10)))
;; => ((2 1) (3 1) (3 2) (4 1) (4 2) (4 3) (5 1) (5 2)
;;     etc.
----

This pattern, where you end with a sequence of sequences of things but you want to get to just a sequence of things, is common enough that it has it's own convention, called the `flatmap`

[source,clojure]
----
(defn flatmap [f xs]
  (accumulate append nil (map f xs)))

(flatmap (fn [i] (map (fn [j] (list i j)) (enumerate-interval 1 (- i 1))))
         (enumerate-interval 1 10))
----

(Note: Flatmap is called `mapcat` in Clojure)

Now, we can answer the original question

[source,clojure]
----
(defn prime-sum? [pair]
  (prime? (+ (first pair) (second pair))))

(defn make-pair-sum [pair]
  (list (first pair) (second pair) (+ (first pair) (second pair))))

(defn prime-sum-pairs [n]
  (->> (enumerate-interval 1 n)
       (flatmap (fn [i] (map (fn [j] (list i j)) (enumerate-interval 1 (- i 1)))))
       (filter prime-sum?)
       (map make-pair-sum)))

(prime-sum-pairs 6)
;; => ((2 1 3) (3 2 5) (4 1 5) (4 3 7) (5 2 7) (6 1 7) (6 5 11))
----

== Symbolic data

=== Example: Symbolic differentiation example

We will write a program to do automatic differentiation, encoding the following rules:

image::../images/book_sicp/1_2_4_diffs1.gif[]
image::../images/book_sicp/1_2_4_diffs2.gif[]
image::../images/book_sicp/1_2_4_diffs3.gif[]
image::../images/book_sicp/1_2_4_diffs4.gif[]

Our initial evaluator looks like this:

[source,clojure]
----
(defn deriv [exp var]
  (cond (number? exp) 0
        (variable? exp) (if (same-variable? exp var) 1 0)
        (sum? exp) (make-sum (deriv (addend exp) var)
                             (deriv (augend exp) var))
        (product? exp) (make-sum (make-product (multiplier exp)
                                               (deriv (multiplicand exp) var))
                                 (make-product (deriv (multiplier exp) var)
                                               (multiplicand exp)))
        :else (throw (ex-info "unknown expression type -- DERIV" exp))))
----

With one cond branch for each rule. There are a number of procedures we need to create (number? is a built-in in Clojure). To do that, we need to decide on a representation of an expression to be evaluated. Since we have perfectly good list-syntax, with `+` and `*` we can use that. So the exp in the above will look like `'(* (* x y) (+ x 3))`.

[source,clojure]
----

(def variable? symbol?)
(defn same-variable? [a b] (and (every? symbol? [a b]) (= a b)))
(defn sum? [expr] (and (seq expr) (= (first expr) '+)))
(defn product? [expr] (and (seq expr) (= (first expr) '*)))
(defn make-sum [e1 e2] (list '+ e1 e2))
(defn make-product [e1 e2] (list '* e1 e2))
(defn addend [expr] (nth expr 1))
(defn augend [expr] (nth expr 2))
(defn multiplier [expr] (nth expr 1))
(defn multiplicand [expr] (nth expr 2))

(deriv 1 'x)
;; => 0
(deriv '(+ x 3) 'x)
;; => (+ 1 0)
(deriv '(* x y) 'x)
;; => (+ (* x 0) (* 1 y))
(deriv '(* (* x y) (+ x 3)) 'x)
;; => (+ (* (* x y) (+ 1 0)) (* (+ (* x 0) (* 1 y)) (+ x 3)))
----

Unfortunately, the terms aren't being simplified. `(+ (* x 0) (* 1 y))` is obviously just `y`.

We can fix that by iterating our make-sum and make-product so they handle the cases where both values are numbers, the identity cases, and (for multiplication) the null cases.

[source,clojure]
----
(defn make-sum [e1 e2]
  (cond (every? number? [e1 e2]) (+ e1 e2)
        (and (number? e1) (zero? e1)) e2
        (and (number? e2) (zero? e2)) e1
        :else (list '+ e1 e2)))

(defn make-product [e1 e2]
  (cond (every? number? [e1 e2]) (* e1 e2)
        (and (number? e1) (zero? e1)) 0
        (and (number? e1) (= 1 e1)) e2
        (and (number? e2) (zero? e2)) 0
        (and (number? e2) (= 1 e2)) e1
        :else (list '* e1 e2)))

(deriv 1 'x)
;; => 0
(deriv '(+ x 3) 'x)
;; => 1
(deriv '(* x y) 'x)
;; => y
(deriv '(* (* x y) (+ x 3)) 'x)
;; => (+ (* x y) (* y (+ x 3)))
----

=== Example: Representing Sets

A set is a collection of distinct objects. They have operations `union` `intersection` `element-of-set?` and `adjoin-set`

The choice for representation here is not so obvious. There are many possibilities.

One way to represent a set is as an unordered list of elements that appear no more than once. In this case the operations could look like this:

[source,clojure]
----
(defn element-of-set? [x set]
  (cond (empty? set) false
        (= x (first set)) true
        :else (element-of-set? x (rest set))))

(defn adjoin-set [x set]
  (if (element-of-set? x set) set
      (cons x set)))

(defn intersection-set [set1 set2]
  (cond (or (empty? set1) (empty? set2)) '()
        (element-of-set? (first set1) set2) (cons (first set1)
                                                  (intersection-set (rest set1) (set2)))
        :else (intersection-set (rest set1) set2)))
----

Consider the efficiency of these operations.

* element-of-set? is O(N) in the worst case (it has to scan every element)
* because adjoin-set tests element of set, it too is O(N)
* Intersection is O(N^2), because it does an element-of-set test for every element of set1

If we could increase the efficiency of element-of-set, we can make all of faster.

Consider an implementation as an _ordered_ list. If we do this, we no longer need to scan the entire list:

[source,clojure]
----
(defn element-of-set? [x set]
  (cond (empty? set) false
        (< x (first set)) false
        (= x (first set)) true
        :else (element-of-set? x (rest set))))
----

On average, we can expect that we will have to examine about half the items in the set. So we can say that, though this is still O(N), we've reduced the time by about a factor of 2.

We can make `intersection` O(N) though.

[source,clojure]
----
(defn intersection-set [set1 set2]
  (cond (or (empty? set1) (empty? set2)) '()
        (= (first set1) (first set2)) (cons (first set1) (intersection-set (rest set1) (rest set2)))
        (< (first set1) (first set2)) (intersection-set (rest set1) set2)
        (> (first set1) (first set2)) (intersection-set set1 (rest set2))))
----

Consider that we have have two lists: `(2 4 6 8 10)` and `(3 4 5 6 7)`

* we test 2 against 3: 2<3 so we recur with `(4 6 8 10)` and `(3 4 5 6 7)`
* 4>3 so we recur with `(4 6 8 10)` and `(4 5 6 7)`
* 4=4 so we cons 4 and recur with `(6 8 10)` and `(5 6 7)`
* 6>5 so we recur with `(6 8 10)` and `(6 7)`
* 6=6 so we cons 6 and recur with `(8 10)` and `(7)`
* 8>7 so we recur with `(8 10)` and `()`
* set 2 is empty, return false, ending up with `(cons 4 (cons 6 false)) => (4 6)` 

At most, we will have number of operations len(set1) + len(set2)

A third representation of sets is as a binary tree. Binary meaning that each node as at most 2 children: a left and right branch.

The special property of the tree that we want is that, with respect to any given node, everything in the _left_ subtree is smaller than the node value, and everything in the _right_ subtree is larger (we don't need to worry about equal to, since a set has no repeated elements). This does mean there can be many representations of the same set. For example {1 3 5 7 9 11} can be represented as. 

image::../images/book_sicp/2_16_set_tree.gif[]

The rationale for doing this is speed. Consider we want to check if 9 is in the set. In an ordered list representation, this would take 5 checks. In the above tree representations it is 2 or 3, depending on tree structure. e.g. in the first one, set 7, then go right, check 9, done.

Comparing the left tree to the ordered list, we can see the number of tests you need to perform (ordered list on the left)

* element-of-set? 1:  1 vs. 3
* element-of-set? 3:  2 vs. 2
* element-of-set? 5:  3 vs. 3
* element-of-set? 7:  4 vs. 1
* element-of-set? 9:  5 vs. 2
* element-of-set? 11: 6 vs. 3

We can see a tree has a maximum of 3 tests. In general, the maximum number of tests for a tree is the height of the tree. This leads to the intuition that shorter trees are better, because it reduces the maximum number of tests. The second tree, for example, has a height of 4, and to check 11 you'd need to do 4 tests. The height of a _balanced_ binary tree of n elements is log2 n. So our element-of-set operation can now be O(log n), which is _much_ faster than O(N).

So we need an abstraction for working with trees. We can again use lists as the underlying structure, where a tree will look like:

`(entry left-subtree right-subtree)`

[source,clojure]
----
(defn entry [tree] (first tree))
(defn left-branch [tree] (second tree))
(defn right-branch [tree] (nth tree 2 nil))
(defn make-tree [entry left-branch right-branch]
  (list entry left-branch right-branch))

(defn element-of-set? [x set]
  (cond (nil? set) false
        (= x (entry set)) true
        (< x (entry set)) (element-of-set? x (left-branch set))
        (> x (entry set)) (element-of-set? x (right-branch set))))

(element-of-set? 6 '(7 (3 (1) (5)) (9 nil (11))))
;; => false
(element-of-set? 5 '(7 (3 (1) (5)) (9 nil (11))))
;; => true
----

element-of-set here just walks the tree - very declarative and easy to understand.

With this representation, we can't just adjoin an element to a set with `cons`, we have to expand the tree.

[source,clojure]
----
(defn adjoin-set [x set]
  (cond (empty? set) (make-tree x nil nil)
        (= x (entry set)) set
        (< x (entry set)) (make-tree (entry set)
                                     (adjoin-set x (left-branch set))
                                     (right-branch set))
        (> x (entry set)) (make-tree (entry set)
                                     (left-branch set)
                                     (adjoin-set x (right-branch set)))))

(adjoin-set 1 '())
;; => (1 nil nil)
(adjoin-set 1 '(2))
;; => (2 (1 nil nil) nil)
(adjoin-set 3 '(2))
;; => (2 nil (3 nil nil))
(adjoin-set 1 '(7 (3 (1) (5)) (9 nil (11))))
;; => (7 (3 (1) (5)) (9 nil (11)))
(adjoin-set 4 '(7 (3 (1) (5)) (9 nil (11))))
;; => (7 (3 (1) (5 (4 nil nil) nil)) (9 nil (11)))
----

Essentially, assuming the element isn't already in the set, this walks the tree until it finds it's 'spot' (a `nil` on the end of a node), then in place of the nil, puts a new element `(x nil nil)` (a leaf node). This is very similar in concept to the element-of operation, and is also O(log n) 

There is a problem here though: Our assumption that the operations are O(log n) are premised on the tree being _balanced_. Consider a tree that looks like this:

image::../images/book_sicp/2_17_tall_tree.gif[]

An element-of operation on this will be O(N), since the height of the tree is N (in fact this is totally equivalent to an ordered list representation). To properly say that this has O(log n) properties, we must make sure the tree is mostly balanced - that is, the size of the left subtrees are about equal to the size of the right subtrees, for all nodes. One way to solve this is to have an operation that 'balances' a tree. This is left as an exercise.

The thought process we've examined here comes up again and again in data focused programs.

=== Example: Huffman Encoding Trees 

ASCII text can be represented as a sequence of seven bits, allowing us to represent (2^7) 128 different characters as binary numbers. In general, a system for representing n symbols will need us to use log2 n bits. These are called *fixed-length codes*. For example, to represent the 8 characters A-H, we could use 3 bits (2^3 = 8)

  A 000 	C 010 	E 100 	G 110
  B 001 	D 011 	F 101 	H 111 

  BACADAEAFABBAAAGAH = 001000010000011000100000101000001001000000000110000111

We could also represent data using a system of *variable-length codes*. For example:

  A 0 	C 1010 	E 1100 	G 1110
  B 100 	D 1011 	F 1101 	H 1111

  BACADAEAFABBAAAGAH = 100010100101101100011010100100000111001111

Saving 20% in length.

One of the problems here is that you need to know when you reach the end of one symbol. You could achieve this with an explicit separator (consider the variable length code _morse code_, where letters are separated with with a pause). Another solution is design your code such that no symbol is represented by a code that is the prefix of another code. Taking the above example, since `A` is represented by 0, no other symbol can be represented by a code that starts with 0, since then you couldn't tell if the `0101` is `0` and `101` or `0101`. 

Huffman encoding is a system which which assigns each symbol a _weight_, corresponding the frequency in which that symbol is expected to occur.

For example, consider system for encoding the letters A-H, with a weight of 8 for A, 3 for B, and one for everything else.

We can construct a tree where the leaves are pairs of `[symbol, weight]`, and the parents are merged sets of their children with `[set of symbols, sum symbol weights]`. 

image::../images/book_sicp/2_18_huffman.gif[]

Using this, we can arrive at the representation for any symbol by the following process: Navigate down the tree until you find the symbol you want. Every time you take a left branch, take a 0, and right, take a 1. To get to D, you go right, left, right, right, so the encoding is `1011`. To decode a bit sequence, you do the same thing: starting with 1011, you go right, left, right, right and get to D.

The 'Best' code is one that minimises the number of tests you have to make. This is where the weights (frequencies) come in. You want to construct the tree such that the most frequent symbols take the least amount of branches to reach.

How to construct such a tree?

Start with a set of symbols/weight pairs:

`{(A 8) (B 3) (C 1) (D 1) (E 1) (F 1) (G 1) (H 1)}`

Find the two elements with the lowest weight, and merge them together

`{(A 8) (B 3) ({C D} 2) (E 1) (F 1) (G 1) (H 1)}`

Repeat a couple of times to get:

`{(A 8) (B 3) ({C D} 2) ({E F} 2) ({G H} 2)}`

On the next merge, you are now unioning two sets:

`{(A 8) (B 3) ({C D} 2) ({E F G H} 4)}`

And ultimately you end up

`{({A B C D E F G H} 17)}`

representing your root node.

[NOTE] 
the below code is quite different from the book, but I thought it was good enough. maybe the exercises will show different.

[source,clojure]
----
(def huff '((A 8) (B 3) (C 1) (D 1) (E 1) (F 1) (G 1) (H 1)))

(defn make-leaf [symbol weight] (list 'leaf symbol weight))
(defn leaf? [x] (= 'leaf (first x)))
(defn symbol-leaf [x] (second x))
(defn weight-leaf [x] (nth x 2))

(leaf? (make-leaf 'A 8)) ;; => true
(symbol-leaf (make-leaf 'A 8)) ;; => A
(weight-leaf (make-leaf 'A 8)) ;; => 8

(defn symbols [node] (if (leaf? node) (list (symbol-leaf node)) (nth node 2)))
(defn weight [node] (if (leaf? node) (weight-leaf node) (nth node 3)))
(defn make-code-tree [left right]
  (list left right (append (symbols left) (symbols right)) (+ (weight left) (weight right))))

(defn left-branch [tree] (first tree))
(defn right-branch [tree] (second tree))

(defn make-huff-tree [codes]
  (let [[fst scd & rst] (sort-by weight codes)]
    (if (= 1 (count codes)) codes
        (make-huff-tree (cons (make-code-tree fst scd) rst)))))

(first (make-huff-tree (map #(apply make-leaf %) huff)))
;; =>
'(((leaf A 8)
   ((((leaf G 1)
      (leaf H 1)
      (G H) 2)
     ((leaf E 1)
      (leaf F 1)
      (E F) 2)
     (G H E F) 4)
    (((leaf C 1)
      (leaf D 1)
      (C D) 2)
     (leaf B 3)
     (C D B) 5)
    (G H E F C D B) 9)
   (A G H E F C D B) 17))

(defn decode-bits [bits tree]
  (cond (leaf? tree) (symbol-leaf tree)
        (zero? (first bits)) (decode-bits (rest bits) (left-branch tree))
        :else (decode-bits (rest bits) (right-branch tree))))

;; Redefining unordered list implementation of element of set
(defn element-of-set? [x set]
  (cond (empty? set) false
        (= x (first set)) true
        :else (element-of-set? x (rest set))))

(defn encode-bits [sym tree]
  (cond (leaf? tree) '()
        (element-of-set? sym (symbols (left-branch tree))) (cons 0 (encode-bits sym (left-branch tree)))
        :else (cons 1 (encode-bits sym (right-branch tree)))))

(encode-bits 'A (first (make-huff-tree (map #(apply make-leaf %) huff)))) ;; => (0)
(encode-bits 'B (first (make-huff-tree (map #(apply make-leaf %) huff)))) ;; => (1 1 1)
(encode-bits 'C (first (make-huff-tree (map #(apply make-leaf %) huff)))) ;; => (1 1 0 0)
(encode-bits 'D (first (make-huff-tree (map #(apply make-leaf %) huff)))) ;; => (1 1 0 1)
(encode-bits 'E (first (make-huff-tree (map #(apply make-leaf %) huff)))) ;; => (1 0 1 0)
(encode-bits 'F (first (make-huff-tree (map #(apply make-leaf %) huff)))) ;; => (1 0 1 1)
(encode-bits 'G (first (make-huff-tree (map #(apply make-leaf %) huff)))) ;; => (1 0 0 0)
(encode-bits 'H (first (make-huff-tree (map #(apply make-leaf %) huff)))) ;; => (1 0 0 1)


(decode-bits '(0) (first (make-huff-tree (map #(apply make-leaf %) huff))))       ;; => A
(decode-bits '(1 1 1) (first (make-huff-tree (map #(apply make-leaf %) huff))))   ;; => B
(decode-bits '(1 1 0 0) (first (make-huff-tree (map #(apply make-leaf %) huff)))) ;; => C
(decode-bits '(1 1 0 1) (first (make-huff-tree (map #(apply make-leaf %) huff)))) ;; => D
(decode-bits '(1 0 1 0) (first (make-huff-tree (map #(apply make-leaf %) huff)))) ;; => E
(decode-bits '(1 0 1 1) (first (make-huff-tree (map #(apply make-leaf %) huff)))) ;; => F
(decode-bits '(1 0 0 0) (first (make-huff-tree (map #(apply make-leaf %) huff)))) ;; => G
(decode-bits '(1 0 0 1) (first (make-huff-tree (map #(apply make-leaf %) huff)))) ;; => H
----

== Multiple Representations for Abstract Data

Data abstraction allows us to write much of our program without depending on a specific representation, by erecting an abstraction barrier.

But what if there is more than one useful representation? For example, complex numbers can be represented in rectangular or polar form, with each being useful in different cases. In the real world, systems are designed by many people over long periods. You might end up with multiple representations that need to be isolated from each other and allow multiple representations to exist in a single program. You also need to allow for _new_ representations to be added as they become necessary without breaking the existing code.

We will get around this by creating *generic procedures* - procedures that can operate on multiple representations, where the type of representation is denoted by a _type tag_.

=== Complex Numbers

Complex numbers can be represented in either rectangular form, with real and imaginary parts (`5 + 4i`) or in polar form, with angle and magnitude `[120,3]`. Both essentially descriptions of points on a 2d plane.

Addition is easy in rectangular form: `(a+bi) + (c+di) = (a+c)+(b+d)i`.

Multiplication is simpler in polar form: `[a,b]*[c,d]=[a+c,b*d]`

The principle of data abstraction states that the user should be able to use all operations without caring about the representation.

To create a system of complex numbers, we should have two constructors `make-from-mag-ang` and `make-from-real-imag`; and four accessors `real-part`, `imag-part`, `magnitude`, `angle`.

Then from these we can easily implement `add-complex` etc. without specifying a representation. To complete the package we have to pick a representation though, and implement `real-part` etc. This can be done with a pair of real,imag, or mag,angle.

Here we are practicing the *principle of least commitment*. We can use either, we don't have to decide until the last minute, thus retaining flexibility.

Or, we can just implement both, which effectively defers the commitment _even later_.

We'll need a way to determine which representation is actually being used. We'll do this with type tags. We'll create another abstraction barrier, where we have `type-tag` and `contents` procedures that can extract the type or content, and a `attach tag` to add the tag.

[source,clojure]
----
(defn attach-tag [type-tag contents] (list type-tag contents))
(def type-tag first)
(def content second)

(defn rectangular? [z] (= 'rectangular (type-tag z)))
(defn polar? [z] (= 'polar (type-tag z)))
----

Now, both representations can have their own procedures - though we have to make sure there are not name collisions, e.g `real-part-rectangular`, `real-part-polar`.

A generic selector will check a datum's type-tag and choose the appropriate concrete implementation.

[source,clojure]
----
(def magnitude-polar first)
(def angle-polar second)

(defn real-part-rectangular [z] (first z))
(defn real-part-polar [z]
  (* (magnitude-polar z) (Math/cos (angle-polar z))))

(defn real-part [z]
  (cond (rectangular? z) (real-part-rectangular (contents z))
        (polar? z) (real-part-polar (contents z))
        :else (throw (ex-info "Unknown type -- REAL PART" z))))
----

Since the complex number arithmetic are defined in terms of `real-part` etc. these will still work with either representation.

----
     Programs that use complex numbers
========== add, sub, mul, div ==============
       Complex arithmetic package
== real-part, imag-part, magnitude, angle ==
       Rectangular  |   Polar
    Representation  | Representation
----

Now we have a system that has 3 relatively independent parts: the arithmetic operations, the rectangular implementation and the polar representation. The two implementations could've been designed separately, as long as they implement a similar interface. 

== Systems with Generic Operations