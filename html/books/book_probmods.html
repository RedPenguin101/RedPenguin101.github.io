<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Probabilistic Models of Cognition</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../css/style.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Probabilistic Models of Cognition</h1>
</header>
<nav id="TOC">
<ul>
<li><a href="#selective-content">Selective content</a></li>
<li><a href="#intro">Intro</a></li>
<li><a href="#generative-models">Generative models</a><ul>
<li><a href="#models-simulation-degrees-of-belief">Models, simulation, degrees of belief</a></li>
<li><a href="#church-building-generative-models">Church, building generative models</a></li>
<li><a href="#simulation-and-probability">Simulation and probability</a></li>
<li><a href="#stochastic-recursion">Stochastic recursion</a></li>
<li><a href="#persistent-randomness-with-memoization">Persistent Randomness with Memoization</a></li>
</ul></li>
</ul>
</nav>
<h1 id="selective-content">Selective content</h1>
<ul>
<li>Generative models</li>
<li>Conditioning</li>
<li>Hierarchical models</li>
<li>Mixture Models</li>
<li>Non-parametric models</li>
</ul>
<h1 id="intro">Intro</h1>
<p>A computation theory of mind: the mind is a computer, <strong>mental representations</strong> are programs, thinking is a computer process.</p>
<p>Generative approach: mental representations are <em>general descriptions</em> about how the world works, <strong>simplified models</strong> that can be used to make inferences. A Generative Model describes a process which generates observable data. Due to sparsity of observations, these models are <em>probabilistic</em>, not deterministic.</p>
<ol type="1">
<li>Stuff happens in the real world, generating facts</li>
<li>We have a generative model, describing a process which generates observations.</li>
<li>The correlation between the actual facts and the hypothetical ones from the model gives clues about the accuracy of that model.</li>
</ol>
<h1 id="generative-models">Generative models</h1>
<h2 id="models-simulation-degrees-of-belief">Models, simulation, degrees of belief</h2>
<p>The mind maintains models of parts of the world, which it can use to simulate this part of the world (i.e. Imagining what follows from initial conditions).</p>
<p>Simulation is related to degrees of belief. The model of a real process allows you to say, ahead of an event, how much you believe a particular outcome will happen. The <em>shape of expected outcomes</em> (the relative belief in all possible outcomes) can be formalized as a probability distribution.</p>
<h2 id="church-building-generative-models">Church, building generative models</h2>
<p>A formal model is a description of a process for how to generate states: the steps that unfold that lead to potentially observable states. These generative process can be described as computations that use random choices to capture uncertainty.</p>
<p>Church is an extended scheme which permits probabilistic computation. It has Exchangeable Random Primitives (XRPs): functions that, when called, results in a samples from a distribution. For example, <code>(flip)</code> simulates a coin flip, and has a 50% chance of returning “true” or “false”.</p>
<p><code>flip</code> can be thought of either as a sampler for generating samples, or a characterization of the distribution itself.</p>
<p>Other distributions are available: <code>gaussian</code>, <code>gamma</code>, <code>dirichlet</code> etc.</p>
<p>They can be combined: <code>(* (gaussian 0 1) (gaussian 0 1))</code>, or, to generate a stochastic function: <code>(lambda () (* (gaussian 0 1) (gaussian 0 1)))</code><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>, or <code>(lambda (x) (if (flip) x (+ x x)))</code></p>
<h2 id="simulation-and-probability">Simulation and probability</h2>
<p>How can we predict the outcome of a simulation? For example, how likely is it that we will see the result <code>(#t #f)</code> from <code>(list (flip) (flip))</code>? This is denoted <span class="math inline"><em>P</em>(<em>A</em>)</span>, the probability of event <span class="math inline"><em>A</em></span>. We could run the program many times and see what fraction of the time the outcome <code>(#t #f)</code> is returned.</p>
<p>The <em>Product Rule</em> states that the probability of two random choices is the product of their individual probabilities: <span class="math inline"><em>P</em>(<em>A</em>, <em>B</em>) = <em>P</em>(<em>A</em>)<em>P</em>(<em>B</em>)</span>. However, this is only if the probabilities of <span class="math inline"><em>A</em></span> and <span class="math inline"><em>B</em></span> are independent. If the events are in sequence, and the outcome of <span class="math inline"><em>B</em></span> could depend on the outcome of <span class="math inline"><em>A</em></span>, we must say that <span class="math inline"><em>B</em></span> is <em>conditioned</em> on <span class="math inline"><em>A</em></span>, written <span class="math inline"><em>P</em>(<em>B</em>|<em>A</em>)</span>. The real product rules is therefore <span class="math inline"><em>P</em>(<em>A</em>, <em>B</em>) = <em>P</em>(<em>A</em>)<em>P</em>(<em>B</em>|<em>A</em>)</span>.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>The <em>Sum Rule</em> is <span class="math inline"><em>P</em>(<em>A</em>) = ∑<sub><em>B</em></sub><em>P</em>(<em>A</em>, <em>B</em>)</span>. Using the sum rule is called <em>Marginalization</em>.</p>
<h2 id="stochastic-recursion">Stochastic recursion</h2>
<p>A normal recursion has a ‘termination condition’, where it will decide when to stop. A stochastic recursion is the same, but it <em>randomly</em> decides when to stop:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode scheme"><code class="sourceCode scheme"><a class="sourceLine" id="cb1-1" title="1"><span class="co">;; A geometric distribution defined as a SR function</span></a>
<a class="sourceLine" id="cb1-2" title="2">(<span class="ex">define</span><span class="fu"> </span>(geometric p)</a>
<a class="sourceLine" id="cb1-3" title="3">  (<span class="kw">if</span> (flip p) <span class="dv">0</span></a>
<a class="sourceLine" id="cb1-4" title="4">    (<span class="op">+</span> <span class="dv">1</span> (geometric p))))</a></code></pre></div>
<h2 id="persistent-randomness-with-memoization">Persistent Randomness with Memoization</h2>
<p>Often we will want the initial sample to be random, but any future samples to be consistent with that initial sample. For example if ‘eye-color’ is a uniform distribution over the values blue, green, brown, then the initial call <code>(eye-color 'bob)</code> might be blue. But since bob’s eye color doesn’t change, subsequent calls to <code>(eye-color 'bob)</code> must also be blue. We can accomplish this <em>persistent randomness</em> with memoization, the <code>mem</code> function.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode scheme"><code class="sourceCode scheme"><a class="sourceLine" id="cb2-1" title="1">(<span class="ex">define</span><span class="fu"> eye-color</span></a>
<a class="sourceLine" id="cb2-2" title="2">  (mem (<span class="kw">lambda</span> (person) (uniform-draw &#39;(blue green brown)))))</a></code></pre></div>
<p>This is sometimes called <em>random world</em> style modeling.</p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>A function with no arguments is called a <em>thunk</em>.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Note that <span class="math inline"><em>P</em>(<em>A</em>, <em>B</em>) = <em>P</em>(<em>B</em>, <em>A</em>)</span>, so <span class="math inline"><em>P</em>(<em>A</em>)<em>P</em>(<em>B</em>|<em>A</em>) = <em>P</em>(<em>B</em>)<em>P</em>(<em>A</em>|<em>B</em>)</span>. This is the foundation of Bayes Theorem.<a href="#fnref2" class="footnote-back">↩</a></p></li>
</ol>
</section>
</body>
</html>
